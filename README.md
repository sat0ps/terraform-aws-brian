# Brian AI Assistant ‚Äî AWS Infrastructure (Terraform)

![Terraform Validate](https://github.com/sat0ps/terraform-aws-brian/actions/workflows/validate.yml/badge.svg)

# Brian AI Assistant - AWS Infrastructure

[![Deploy to AWS](https://github.com/sat0ps/terraform-aws-brian/workflows/Deploy%20Brian%20AI%20to%20AWS/badge.svg)](https://github.com/sat0ps/terraform-aws-brian/actions)
[![Terraform](https://img.shields.io/badge/terraform-%235835CC.svg?style=for-the-badge&logo=terraform&logoColor=white)](https://terraform.io/)
[![AWS](https://img.shields.io/badge/AWS-%23FF9900.svg?style=for-the-badge&logo=amazon-aws&logoColor=white)](https://aws.amazon.com/)
[![Kubernetes](https://img.shields.io/badge/kubernetes-%23326ce5.svg?style=for-the-badge&logo=kubernetes&logoColor=white)](https://kubernetes.io/)

> **Enterprise-grade AWS infrastructure for Brian AI Assistant v2.0** - Modular Terraform for AWS to run Brian v2 with offline LLMs via Ollama, Electron GUI, and advanced safety parsing with >95% command execution accuracy.

## üöÄ Project Overview

Brian AI Assistant is a sophisticated AI system designed to interpret system-level tasks in natural language with exceptional accuracy. This repository contains modular, production-ready AWS infrastructure as code (IaC) using Terraform, enabling scalable, secure, and cost-effective deployment on Amazon Web Services.

### üéØ Key Features

- **üß† Dual AI Models**: LLaMA 3 & Mistral via Ollama for enhanced accuracy
- **‚ö° High Performance**: >95% command execution accuracy
- **üõ°Ô∏è Enhanced Security**: Safety parsing blocking malformed/harmful instructions (40% reliability improvement)  
- **üéÆ Intuitive Interface**: Hotkey-activated Electron GUI
- **üì± Full Offline Capability**: No internet dependency required
- **üîß System Integration**: Direct Linux system-level task execution
- **üìä Enterprise Monitoring**: Comprehensive logging and metrics via CloudWatch
- **üîê AWS Native Security**: IAM, Secrets Manager, and VPC isolation

## üèóÔ∏è Architecture Overview

```mermaid
graph TB
    subgraph "AWS Cloud Infrastructure"
        subgraph "Networking Layer"
            VPC[VPC with Public/Private Subnets<br/>10.0.0.0/16]
            ALB[Application Load Balancer<br/>Public Access]
            NAT[NAT Gateway<br/>Outbound Internet]
            IGW[Internet Gateway<br/>Public Access]
        end
        
        subgraph "Compute Layer - EKS"
            EKS[Amazon EKS Cluster<br/>Kubernetes 1.28+]
            SystemNodes[System Node Group<br/>t3.medium instances]
            GPUNodes[GPU Node Group<br/>p3.2xlarge (optional)]
            ALBController[AWS Load Balancer Controller<br/>Ingress Management]
        end
        
        subgraph "AI Services"
            LLaMA[LLaMA 3 Service<br/>Natural Language Processing]
            Mistral[Mistral Service<br/>Command Interpretation]
            Ollama[Ollama Runtime<br/>Local AI Inference]
            Safety[Safety Parser<br/>Malicious Code Detection]
        end
        
        subgraph "Storage & Registry"
            ECR[Amazon ECR<br/>Container Registry]
            EBS[EBS Volumes<br/>Persistent Storage]
            S3[S3 Buckets<br/>Model Artifacts & Logs]
            SecretsManager[AWS Secrets Manager<br/>API Keys & Configs]
        end
        
        subgraph "Security & Monitoring"
            IAM[IAM Roles & Policies<br/>Fine-grained Access]
            SecretsCSI[Secrets Store CSI Driver<br/>Pod Secret Injection]
            CloudWatch[CloudWatch<br/>Metrics & Logs]
            GuardDuty[GuardDuty<br/>Threat Detection]
        end
    end
    
    subgraph "External"
        User[üë§ User]
        GUI[Electron GUI]
        Linux[Linux System]
        GitHub[GitHub Actions<br/>CI/CD Pipeline]
    end
    
    User --> GUI
    GUI --> ALB
    ALB --> EKS
    EKS --> LLaMA
    EKS --> Mistral
    LLaMA --> Ollama
    Mistral --> Ollama
    Ollama --> Safety
    Safety --> Linux
    
    EKS --> ECR
    EKS --> EBS
    EKS --> SecretsCSI
    SecretsCSI --> SecretsManager
    EKS --> CloudWatch
    GitHub --> ECR
    GitHub --> EKS
```

## üìã Prerequisites

- **AWS Account** with appropriate permissions
- **Terraform** >= 1.6.0
- **AWS CLI** >= 2.13.0 
- **kubectl** >= 1.28.0
- **Docker** >= 24.0.0 (for local testing)
- **Git** for version control

## üöÄ Quick Start

### 1. Clone Repository
```bash
git clone https://github.com/sat0ps/terraform-aws-brian.git
cd terraform-aws-brian
```

### 2. Configure AWS Authentication
```bash
# Configure AWS CLI
aws configure

# Or export environment variables
export AWS_ACCESS_KEY_ID="your-access-key"
export AWS_SECRET_ACCESS_KEY="your-secret-key"
export AWS_DEFAULT_REGION="us-east-1"

# Verify access
aws sts get-caller-identity
```

### 3. Setup Terraform Backend (Optional)
```bash
# Create S3 bucket for Terraform state
aws s3 mb s3://terraform-state-brian-ai-$(date +%s) --region us-east-1

# Create DynamoDB table for state locking
aws dynamodb create-table \
    --table-name terraform-state-lock-brian-ai \
    --attribute-definitions AttributeName=LockID,AttributeType=S \
    --key-schema AttributeName=LockID,KeyType=HASH \
    --provisioned-throughput ReadCapacityUnits=5,WriteCapacityUnits=5 \
    --region us-east-1
```

### 4. Development Environment (Quick Start)
```bash
# Navigate to dev environment
cd envs/dev

# Initialize Terraform (backend-free for development)
terraform init -backend=false

# Validate configuration
terraform validate

# Plan deployment
terraform plan

# Apply infrastructure (with confirmation)
terraform apply
```

### 5. Production Deployment
```bash
# Navigate to production environment  
cd envs/prod

# Configure backend (replace with your bucket name)
terraform init \
  -backend-config="bucket=your-terraform-state-bucket" \
  -backend-config="key=brian-ai/prod/terraform.tfstate" \
  -backend-config="region=us-east-1" \
  -backend-config="dynamodb_table=terraform-state-lock-brian-ai"

# Plan and apply
terraform plan -var-file="terraform.tfvars"
terraform apply -var-file="terraform.tfvars"
```

### 6. Connect to EKS Cluster
```bash
# Update kubeconfig
aws eks update-kubeconfig --region us-east-1 --name $(terraform output -raw eks_cluster_name)

# Verify connection
kubectl get nodes
kubectl get pods -n app-brian
```

## üîß Configuration

### Module Structure
```
terraform-aws-brian/
‚îú‚îÄ‚îÄ modules/                        # Reusable Terraform modules
‚îÇ   ‚îú‚îÄ‚îÄ aws-vpc/                   # VPC with public/private subnets + NAT
‚îÇ   ‚îú‚îÄ‚îÄ aws-eks/                   # EKS cluster with node groups
‚îÇ   ‚îú‚îÄ‚îÄ aws-ecr/                   # Elastic Container Registry
‚îÇ   ‚îú‚îÄ‚îÄ aws-secrets/               # Secrets Manager integration
‚îÇ   ‚îú‚îÄ‚îÄ aws-monitoring/            # CloudWatch, GuardDuty setup
‚îÇ   ‚îî‚îÄ‚îÄ app-brian/                 # Brian AI application deployment
‚îú‚îÄ‚îÄ envs/                          # Environment-specific configurations
‚îÇ   ‚îú‚îÄ‚îÄ dev/                       # Development environment
‚îÇ   ‚îú‚îÄ‚îÄ staging/                   # Staging environment
‚îÇ   ‚îî‚îÄ‚îÄ prod/                      # Production environment
‚îú‚îÄ‚îÄ charts/                        # Helm charts for applications
‚îú‚îÄ‚îÄ scripts/                       # Helper scripts
‚îî‚îÄ‚îÄ .github/workflows/             # CI/CD pipelines
```

### Environment Configuration

#### Development Environment (`envs/dev/terraform.tfvars`)
```hcl
# Basic configuration for development
environment = "dev"
region      = "us-east-1"

# EKS Configuration
eks_cluster_name    = "brian-ai-dev"
kubernetes_version  = "1.28"
enable_gpu_nodes   = false  # Cost optimization

# Node groups
system_node_config = {
  instance_types = ["t3.medium"]
  min_size      = 1
  max_size      = 3
  desired_size  = 2
}

# Skip GPU nodes for development
gpu_node_config = {
  enabled = false
}

# ECR Configuration  
ecr_repositories = [
  "brian-ai/llama",
  "brian-ai/mistral", 
  "brian-ai/api"
]

# Brian AI Configuration
brian_config = {
  replica_count          = 1
  safety_parsing_enabled = true
  resource_limits = {
    cpu    = "500m"
    memory = "2Gi"
  }
}
```

#### Production Environment (`envs/prod/terraform.tfvars`)
```hcl
# Production configuration
environment = "prod"
region      = "us-east-1"

# EKS Configuration
eks_cluster_name    = "brian-ai-prod"
kubernetes_version  = "1.28"
enable_gpu_nodes   = true

# System nodes
system_node_config = {
  instance_types = ["t3.large"]
  min_size      = 2
  max_size      = 10
  desired_size  = 3
}

# GPU nodes for AI inference
gpu_node_config = {
  enabled        = true
  instance_types = ["p3.2xlarge"]
  min_size      = 1
  max_size      = 5
  desired_size  = 2
  taints = [{
    key    = "nvidia.com/gpu"
    value  = "true"
    effect = "NO_SCHEDULE"
  }]
}

# High availability Brian AI
brian_config = {
  replica_count          = 3
  safety_parsing_enabled = true
  resource_limits = {
    cpu    = "2000m"
    memory = "8Gi"
    gpu    = "1"
  }
}
```

## üîê Security Features

### AWS Native Security
- **VPC Isolation**: Private subnets for EKS worker nodes
- **Security Groups**: Restrictive inbound/outbound rules
- **IAM Roles**: Fine-grained permissions for services
- **Secrets Manager**: Secure storage of API keys and configurations
- **GuardDuty**: Threat detection and monitoring

### Container Security
- **ECR Image Scanning**: Vulnerability detection in container images
- **Pod Security Standards**: Kubernetes security policies
- **Network Policies**: Micro-segmentation between services
- **Service Mesh**: Optional Istio integration for advanced security

### Safety Parsing
- **Input Validation**: Sanitization of all user commands
- **Command Pattern Blocking**: Prevention of dangerous operations
- **Rate Limiting**: Protection against abuse
- **Audit Logging**: Complete trail of all operations

### Secrets Management
```yaml
# Example secrets stored in AWS Secrets Manager
brian-ai/api-keys:
  openai_api_key: "sk-..."
  anthropic_key: "claude-..."
  
brian-ai/config:
  database_url: "postgresql://..."
  redis_url: "redis://..."
  jwt_secret: "random-secret"
```

## üìä Monitoring & Observability

### CloudWatch Integration
```yaml
Metrics Collected:
  - EKS cluster health and performance
  - Application response times and error rates
  - AI model inference latency and accuracy
  - Resource utilization (CPU, Memory, GPU)
  - Security events and blocked requests

Log Groups:
  - /aws/eks/brian-ai-dev/cluster
  - /aws/containerinsights/brian-ai-dev/application
  - /brian-ai/api-logs
  - /brian-ai/model-inference
  - /brian-ai/safety-parser
```

### Dashboards Available
- **EKS Cluster Overview**: Node health, pod status, resource usage
- **Brian AI Performance**: Model accuracy, response times, request volume  
- **Security Dashboard**: Threat detection, blocked requests, access patterns
- **Cost Management**: Resource costs, optimization recommendations

### Alerting Rules
```yaml
Critical Alerts:
  - EKS cluster node failure
  - Application error rate > 5%
  - AI model accuracy drop < 90%
  - Security threat detection

Warning Alerts:
  - High resource utilization > 80%
  - Slow API response time > 2s
  - Unusual request patterns
  - Cost budget threshold exceeded
```

## üí∞ Cost Optimization

### Estimated Monthly Costs (USD)

| Component | Development | Production | Notes |
|-----------|-------------|------------|-------|
| EKS Control Plane | $73 | $73 | Fixed cost per cluster |
| System Nodes (t3.medium/large) | $60-90 | $180-300 | 2-3 nodes |
| GPU Nodes (p3.2xlarge) | $0 | $600-1500 | 1-2 nodes when enabled |
| ECR Storage | $5-10 | $20-30 | Container images |
| S3 Storage | $5-10 | $15-25 | Logs and artifacts |
| CloudWatch | $10-20 | $30-50 | Metrics and logs |
| NAT Gateway | $45 | $135 | 1-3 AZs |
| Load Balancer | $25 | $50 | ALB instances |
| **Total** | **$223-293** | **$1,103-2,163** | Variable based on usage |

### Cost Optimization Strategies

#### Development Environment
```hcl
# Use Spot Instances for non-critical workloads
spot_instance_config = {
  enabled = true
  instance_types = ["t3.medium", "t3.large"]
  spot_allocation_strategy = "diversified"
}

# Scale down during off-hours
cluster_autoscaler = {
  enabled = true
  scale_down_delay_after_add = "10m"
  scale_down_unneeded_time   = "10m"
}
```

#### Production Environment
```hcl
# Reserved Instances for predictable workloads
reserved_instances = {
  system_nodes = {
    instance_type = "t3.large"
    count        = 2
    term         = "1year"
  }
}

# Savings Plans for compute
savings_plan = {
  compute_savings_plan = "EC2ComputeSavingsPlans"
  commitment          = "$100/month"
}
```

### Resource Management
- **Horizontal Pod Autoscaler (HPA)**: Scale based on CPU/memory/custom metrics
- **Vertical Pod Autoscaler (VPA)**: Right-size container resources
- **Cluster Autoscaler**: Add/remove nodes based on demand
- **Karpenter**: Advanced node provisioning and optimization

## üîÑ CI/CD Pipeline

### GitHub Actions Workflow

```yaml
# .github/workflows/deploy.yml
name: Deploy Brian AI to AWS
on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

jobs:
  terraform-plan:
    runs-on: ubuntu-latest
    outputs:
      environment: ${{ steps.set-env.outputs.environment }}
    steps:
      - uses: actions/checkout@v4
      - uses: hashicorp/setup-terraform@v3
      - name: AWS Configure
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1
      - name: Terraform Plan
        run: |
          cd envs/dev
          terraform init
          terraform plan

  build-and-push:
    needs: terraform-plan
    runs-on: ubuntu-latest
    strategy:
      matrix:
        service: [llama, mistral, api]
    steps:
      - uses: actions/checkout@v4
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1
      - name: Login to Amazon ECR
        uses: aws-actions/amazon-ecr-login@v2
      - name: Build and push Docker image
        run: |
          ECR_URI=$(aws ecr describe-repositories --repository-names brian-ai/${{ matrix.service }} --query 'repositories[0].repositoryUri' --output text)
          docker build -f docker/Dockerfile.${{ matrix.service }} -t $ECR_URI:$GITHUB_SHA .
          docker push $ECR_URI:$GITHUB_SHA

  deploy:
    needs: [terraform-plan, build-and-push]
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Deploy to EKS
        run: |
          aws eks update-kubeconfig --region us-east-1 --name brian-ai-dev
          kubectl apply -f k8s/
          kubectl set image deployment/brian-ai-llama brian-ai-llama=$ECR_URI:$GITHUB_SHA -n app-brian
```

### Branch Strategy
- **`main`** ‚Üí Production deployment (manual approval required)
- **`develop`** ‚Üí Staging deployment (automatic)
- **Feature branches** ‚Üí Development environment (automatic)

### Required Secrets
```yaml
AWS_ACCESS_KEY_ID: "your-aws-access-key"
AWS_SECRET_ACCESS_KEY: "your-aws-secret-key"
ECR_REGISTRY: "123456789012.dkr.ecr.us-east-1.amazonaws.com"
KUBE_CONFIG_DATA: "base64-encoded-kubeconfig"
```

## üö¶ API Usage

### Health Check Endpoints
```bash
# Cluster health
curl -X GET "https://your-alb-dns/health"

# Service-specific health
curl -X GET "https://your-alb-dns/api/v1/health/llama"
curl -X GET "https://your-alb-dns/api/v1/health/mistral"
```

### Execute Command
```bash
curl -X POST "https://your-alb-dns/api/v1/execute" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $API_TOKEN" \
  -d '{
    "query": "show system processes consuming most CPU",
    "model": "llama3",
    "safety_check": true,
    "timeout": 30
  }'
```

### Response Format
```json
{
  "status": "success",
  "request_id": "req_123456",
  "command": "ps aux --sort=-%cpu | head -10",
  "output": "PID  %CPU %MEM COMMAND\n1234  15.2  2.1 python app.py\n...",
  "safety_check": "passed",
  "execution_time": 0.245,
  "model_used": "llama3",
  "confidence_score": 0.96,
  "metadata": {
    "node_id": "worker-node-1",
    "timestamp": "2024-01-15T10:30:00Z"
  }
}
```

## üì± Application Components

### Brian AI Services Architecture
```yaml
Services:
  brian-ai-llama:
    image: ECR_URI/brian-ai/llama:latest
    replicas: 2
    resources:
      limits:
        memory: "8Gi"
        cpu: "2000m"
        nvidia.com/gpu: 1
    
  brian-ai-mistral:  
    image: ECR_URI/brian-ai/mistral:latest
    replicas: 2
    resources:
      limits:
        memory: "8Gi" 
        cpu: "2000m"
        nvidia.com/gpu: 1
        
  brian-ai-api:
    image: ECR_URI/brian-ai/api:latest
    replicas: 3
    resources:
      limits:
        memory: "4Gi"
        cpu: "1000m"

  safety-parser:
    image: ECR_URI/brian-ai/safety:latest
    replicas: 2  
    resources:
      limits:
        memory: "2Gi"
        cpu: "500m"
```

### Persistent Storage
```yaml
# Model cache storage
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: brian-ai-model-cache
  namespace: app-brian
spec:
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 100Gi
  storageClassName: efs-sc  # Amazon EFS for shared storage
```

## üè∑Ô∏è Terraform Outputs

```hcl
# Important outputs from terraform apply
output "eks_cluster_name" {
  description = "Name of the EKS cluster"
  value       = module.eks.cluster_name
}

output "eks_cluster_endpoint" {
  description = "EKS cluster endpoint"  
  value       = module.eks.cluster_endpoint
}

output "ecr_repository_urls" {
  description = "ECR repository URLs"
  value       = module.ecr.repository_urls
}

output "load_balancer_dns" {
  description = "Application Load Balancer DNS name"
  value       = module.alb.dns_name
}

output "brian_ai_endpoints" {
  description = "Brian AI service endpoints"
  value = {
    api_endpoint     = "https://${module.alb.dns_name}/api/v1"
    health_endpoint  = "https://${module.alb.dns_name}/health"
    metrics_endpoint = "https://${module.alb.dns_name}/metrics"
  }
}
```

## üîç Troubleshooting

### Common Issues

#### EKS Node Group Issues
```bash
# Check node status
kubectl get nodes -o wide

# Describe problematic nodes
kubectl describe node NODE_NAME

# Check auto-scaling events
kubectl get events -n kube-system --sort-by='.firstTimestamp'
```

#### Pod Scheduling Issues
```bash
# Check pod status and events
kubectl get pods -n app-brian -o wide
kubectl describe pod POD_NAME -n app-brian

# Check node capacity and taints
kubectl describe nodes | grep -A5 -B5 "Taints\|Capacity"
```

#### GPU Node Issues
```bash
# Verify GPU operator installation
kubectl get pods -n gpu-operator

# Check GPU availability on nodes
kubectl get nodes -l node.kubernetes.io/instance-type=p3.2xlarge

# Test GPU allocation
kubectl apply -f - <<EOF
apiVersion: v1
kind: Pod
metadata:
  name: gpu-test
spec:
  containers:
  - name: gpu-container
    image: nvidia/cuda:11.0-runtime-ubuntu18.04
    command: ["/bin/bash"]
    args: ["-c", "nvidia-smi && sleep 3600"]
    resources:
      limits:
        nvidia.com/gpu: 1
  nodeSelector:
    node.kubernetes.io/instance-type: p3.2xlarge
EOF
```

### Performance Optimization

#### Model Loading Optimization
```yaml
# Use init containers for model pre-loading
initContainers:
- name: model-downloader
  image: alpine/curl
  command: ['sh', '-c']
  args:
    - 'curl -o /models/llama3.gguf https://huggingface.co/...'
  volumeMounts:
  - name: model-cache
    mountPath: /models
```

#### Memory and CPU Tuning
```yaml
# Optimized resource requests and limits
resources:
  requests:
    memory: "4Gi"    # Guaranteed memory
    cpu: "1000m"     # Guaranteed CPU
  limits:  
    memory: "8Gi"    # Maximum memory
    cpu: "2000m"     # Maximum CPU
    nvidia.com/gpu: 1 # GPU allocation
```

## ü§ù Contributing

1. **Fork** the repository
2. Create a **feature branch** (`git checkout -b feature/aws-enhancement`)
3. **Commit** your changes (`git commit -m 'Add AWS optimization'`) 
4. **Push** to the branch (`git push origin feature/aws-enhancement`)
5. Open a **Pull Request**

### Development Guidelines
- Follow Terraform best practices and AWS Well-Architected principles
- Include comprehensive documentation and inline comments
- Add tests for new modules using `terratest`
- Update README for significant changes
- Ensure cost optimization considerations

### Module Development Standards
```hcl
# Example module structure
module "example" {
  source = "./modules/aws-example"
  
  # Required variables
  name        = var.example_name
  environment = var.environment
  
  # Optional variables with defaults
  enable_monitoring = var.enable_monitoring
  
  # Tags for resource management
  tags = merge(
    var.common_tags,
    {
      Module = "aws-example"
    }
  )
}
```

## üìö Additional Resources

### AWS Documentation
- **[Amazon EKS User Guide](https://docs.aws.amazon.com/eks/latest/userguide/)**
- **[AWS Load Balancer Controller](https://kubernetes-sigs.github.io/aws-load-balancer-controller/)**
- **[Amazon ECR User Guide](https://docs.aws.amazon.com/ecr/latest/userguide/)**
- **[AWS Secrets Manager](https://docs.aws.amazon.com/secretsmanager/)**

### Terraform Resources
- **[Terraform AWS Provider](https://registry.terraform.io/providers/hashicorp/aws/latest/docs)**
- **[AWS EKS Terraform Module](https://github.com/terraform-aws-modules/terraform-aws-eks)**
- **[AWS VPC Terraform Module](https://github.com/terraform-aws-modules/terraform-aws-vpc)**

### AI and ML Resources  
- **[Ollama Documentation](https://ollama.ai/docs)**
- **[NVIDIA GPU Operator](https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/)**
- **[Kubeflow on AWS](https://www.kubeflow.org/docs/distributions/aws/)**

### Best Practices
- **[AWS Well-Architected Framework](https://aws.amazon.com/architecture/well-architected/)**
- **[Kubernetes Best Practices](https://kubernetes.io/docs/concepts/configuration/overview/)**
- **[Terraform Best Practices](https://www.terraform.io/docs/cloud/guides/recommended-practices/index.html)**

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üÜò Support

- **Issues**: [GitHub Issues](https://github.com/sat0ps/terraform-aws-brian/issues)
- **Discussions**: [GitHub Discussions](https://github.com/sat0ps/terraform-aws-brian/discussions)
- **AWS Support**: Use AWS Support Center for infrastructure issues
- **Community**: Join our Discord server for real-time help

## üèÜ Acknowledgments

- **Meta AI** for the LLaMA 3 model
- **Mistral AI** for the Mistral model
- **Ollama** for the local AI runtime
- **HashiCorp** for Terraform
- **Amazon Web Services** for cloud infrastructure
- **Kubernetes Community** for container orchestration
- **NVIDIA** for GPU computing support

## üìà Roadmap

### Planned Features
- **Multi-region deployment** support
- **GitOps integration** with ArgoCD/Flux
- **Service mesh** integration (Istio/Linkerd)
- **Advanced monitoring** with Prometheus/Grafana  
- **Cost optimization** automation
- **Compliance scanning** integration
- **Backup and disaster recovery** automation

### Version History
- **v2.0** - AWS EKS deployment with GPU support
- **v1.5** - Safety parsing and security enhancements
- **v1.0** - Initial Brian AI Assistant with offline capability

---

**‚≠ê Star this repository if you find it useful!**

Built with ‚ù§Ô∏è for the AWS and AI community

*Ready to deploy your Brian AI Assistant on AWS? Get started with `terraform apply`!*
